{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> \n",
    "### <u>КОММЕНТАРИЙ РЕВЬЮЕРА</u>\n",
    "</font>\n",
    "\n",
    "<font color='blue'>\n",
    "<br />\n",
    "Никита, доброго дня! рад приветствовать тебя) <br />\n",
    "(а дальше шаболннная обящательная часть, как ты заметил по другим спринтам)\n",
    "<br />    \n",
    "\n",
    "<br />\n",
    "Меня зовут Николай Шавлюго. <br />И на этом этапе твоего движения к новой профессии от меня будут комментарии по написанному коду. <br />Чтобы меньше \"мусорить эфир\" и чтобы максимально наглядно отделяться от основного кода, есть предложение условиться в некоторых обозначениях:<br /> <br />\n",
    "<u><b>ТАКОЙ ШРИФТ</b></u> - всегда начало комментария <br />\n",
    "<font color='green'>такой шрифт</font> - комментарии о том, что всё ОК <br/>\n",
    "<font color='orange'>такой шрифт</font> - комментарии о том, что всё ОК по результату,<br> однако есть на что обратить внимание в плане применения техник, или есть способы сделать более короткий или быстрый код <br/>\n",
    "<font color='red'>такой шрифт</font> - комментарии о том, что есть критичный момент, влияющий на бизнес-результат проекта.<br/>\n",
    "</font><br /><br />\n",
    "<font color='green'>Моей целью является не \"уличить\" в не знании, а просто высказать сверху твоих знаний - свой опыт, что бы ты мог использовать его для своего дальнейшего успеха) И очень здорово будет, если тебе удастся задавать вопросы, да и вообще - всячески доставать меня, если я по каким-то причинам не приму проект:) При этом, из своего опыта скажу, хорошо и важно, когда переписка ревьюера и студента - сохраняется на следующие проекты и даже на будущую практическую деятельность.<br><BR> В ПУТЬ!<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "### Инструкция по выполнению проекта\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #FFFFCC\">Никак не получается добиться результата f1_score на тесте. Подскажите, что делаю не так. На CatBoost на тренировочной выборке обучаетсяя до f1 в районе 0.99, а на тесте низкие результаты</span>\n",
    "\n",
    "<span style=\"background-color: #00FF00\">Всё получилось, спасибо!</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #cceeaa; padding: 5px; border: 1px solid green; border-radius: 5px;\">\n",
    "    <font color='blue'> <b><u>КОММЕНТАРИЙ РЕВЬЮЕРА 2</u></b>\n",
    "</font>\n",
    "<font color='green'><br>Привет, Артём!<br>\n",
    "ОК, здорово.<br>\n",
    "Спасибо за проект) УСПЕШНОГО ДАЛЬНЕЙШЕГО ОБУЧЕНИЯ!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Загрузка модулей__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# обработка текстов\n",
    "import re \n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "nltk.download('stopwords') \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#обработка данных\n",
    "from tqdm import tqdm\n",
    "from tqdm import notebook\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# игнор предупреждений\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "# обучение модели \n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оглавление\n",
    "---\n",
    "\n",
    "##### Часть 1. Подготовка:\n",
    "* [1.1. Загрузка данных.](#1-bullet)\n",
    "* [1.2. Лемматизация и токенизация.](#2-bullet)\n",
    "\n",
    "\n",
    "##### Часть 2. Обучение:\n",
    "* [2.1. Векторизация.](#3-bullet)\n",
    "* [2.2. Построение модели.](#4-bullet)\n",
    "\n",
    "##### Часть 3. Вывод.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #cceeaa; padding: 5px; border: 1px solid green; border-radius: 5px;\">\n",
    "    <font color='blue'> <b><u>КОММЕНТАРИЙ РЕВЬЮЕРА</u></b>\n",
    "</font>\n",
    "<font color='green'><br>\n",
    "план понятен)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1.1 Загрузка данных__\n",
    "<a id='1-bullet'></a>\n",
    "\n",
    "Удаляем дубликаты и пропущенные значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/datasets/toxic_comments.csv')\n",
    "df = df.dropna().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем список признаков и целевого значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=list(df['text'])\n",
    "target =df.toxic.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #cceeaa; padding: 5px; border: 1px solid green; border-radius: 5px;\">\n",
    "    <font color='blue'> <b><u>КОММЕНТАРИЙ РЕВЬЮЕРА</u></b>\n",
    "</font>\n",
    "<font color='green'><br>\n",
    "ок, данные на базе)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1.2. Лемматизация и токенизация__\n",
    "   <a id='2-bullet'></a> \n",
    "- оставляем в тексте только латинские символы\n",
    "- лемматизируем с помощью pymystem3\n",
    "- удаляем стоп-слова\n",
    "- разделяем на токены"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159571/159571 [03:22<00:00, 786.49it/s] \n"
     ]
    }
   ],
   "source": [
    "m = WordNetLemmatizer()\n",
    "from nltk.tokenize import word_tokenize\n",
    "def lemmatize(text):\n",
    "    doc=[]\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    lem_text = [m.lemmatize(i) for i in word_tokenize(text)]\n",
    "    lem_text = \" \".join(lem_text)\n",
    "    return lem_text\n",
    "  \n",
    "processed_texts = Parallel(n_jobs=-1)(delayed(lemmatize)(i) for i in tqdm(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вывод__ WordNetLemmatizer работает в разы быстрее остальных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем новую таблицу из полученных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.Series(processed_texts)\n",
    "new_df = pd.concat([new_df,df.toxic], axis=1)\n",
    "new_df.columns = ['text','toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  toxic\n",
      "0  Explanation Why the edits made under my userna...      0\n",
      "1  D aww He match this background colour I m seem...      0\n",
      "2  Hey man I m really not trying to edit war It s...      0\n",
      "3  More I can not make any real suggestion on imp...      0\n",
      "4  You sir are my hero Any chance you remember wh...      0\n"
     ]
    }
   ],
   "source": [
    "print(new_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.1. Векторизация__\n",
    "<a id='3-bullet'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "count_tf_idf.fit(X_TRAIN)\n",
    "f_train = count_tf_idf.transform(X_TRAIN)\n",
    "f_test = count_tf_idf.transform(X_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #cceeaa; padding: 5px; border: 1px solid green; border-radius: 5px;\">\n",
    "    <font color='blue'> <b><u>КОММЕНТАРИЙ РЕВЬЮЕРА</u></b>\n",
    "</font>\n",
    "<font color='green'><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2.2. Построение модели__\n",
    "<a id='4-bullet'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Разделение на тестовую и тренировочную выборки__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN, X_TEST, Y_TRAIN, Y_TEST = train_test_split(new_df['text'].values,new_df.toxic.values, test_size = 0.2,stratify=new_df.toxic.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Выравнивание классов__\n",
    "Количество токсичных твитов значительно меньше чем, не токсичных, что может вызвать переобучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw = [1,(Y_TRAIN==0).sum() / (Y_TRAIN==1).sum()]\n",
    "print(cw)\n",
    "a={}\n",
    "a[1] = cw[0]\n",
    "a[0] = cw[1]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__GridSearch для CatBoost__\n",
    "Подберем лучшие параметры для модели CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(loss_function='Logloss',early_stopping_rounds=3)\n",
    "\n",
    "grid = {'learning_rate': [0.03, 0.1],\n",
    "        'depth': [4, 6, 10],\n",
    "        'l2_leaf_reg': [1, 3, 5, 7, 9]}\n",
    "\n",
    "grid_search_result = model.grid_search(grid, \n",
    "                                       X=x_train, \n",
    "                                       y=y_train,\n",
    "                                       stratified=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вывод__\n",
    "Лучший результат: depth=4, l2_leaf_reg = 9,learning_rate = 0.1\n",
    "\n",
    "__CatBoostClassifier__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4311382\ttotal: 3.42s\tremaining: 57m 1s\n",
      "200:\tlearn: 0.8629054\ttotal: 9m 28s\tremaining: 37m 41s\n",
      "400:\tlearn: 0.8921253\ttotal: 18m 46s\tremaining: 28m 2s\n",
      "600:\tlearn: 0.9083995\ttotal: 27m 57s\tremaining: 18m 33s\n",
      "800:\tlearn: 0.9190818\ttotal: 37m 14s\tremaining: 9m 15s\n",
      "999:\tlearn: 0.9274896\ttotal: 46m 32s\tremaining: 0us\n",
      "0.751145038167939\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostClassifier(depth=4, l2_leaf_reg = 9,class_weights=cw,learning_rate = 0.1, eval_metric='F1',verbose=200)\n",
    "model.fit(f_train, Y_TRAIN)\n",
    "print(f1_score(model.predict(f_test),Y_TEST))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вывод__ Лучший результат на тестовой выборке :0.751"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Логистическая регрессия__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7734265734265734\n"
     ]
    }
   ],
   "source": [
    "logit = LogisticRegression(random_state=12345, penalty='l1', solver='saga', max_iter=1000,multi_class='ovr')\n",
    "\n",
    "logit.fit(f_train, Y_TRAIN)\n",
    "preds_lr = logit.predict(f_test)\n",
    "print(f1_score(preds_lr,Y_TEST))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вывод__ Лучший результат на тестовой выборке :0.773"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- WordNetLemmatizer дает наиболее быструю обработку текстов.\n",
    "- CatBoostClassifier (с подбором параметром GridSearch) и логистическая регрессия выполняют заданное требование, однако при обучении модели логистической регрессии результат f1_score на тестовой выборке чуть выше.\n",
    "- TF-IDF vectorizer даёт достаточно быструю обработку данных и хорошие результаты при обучении модели.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #cceeaa; padding: 5px; border: 1px solid green; border-radius: 5px;\">\n",
    "    <font color='blue'> <b><u>КОММЕНТАРИЙ РЕВЬЮЕРА</u></b>\n",
    "</font>\n",
    "<font color='green'><br>\n",
    "Никита, \n",
    "Идейные шаги  у тебя - ОК и это очень хорошо!!!. Всё дело в деталях (как обычно).<br>\n",
    "Ниже я приведу алгоритм, по которому предлагаю тебе скорректировтаь код. Т.е. даже сократить код - лучше сказать)<br>\n",
    "В нём только основные шаги, с относительно простыми реализациями. Попробуй так, это долно помочь достчь результат. И заодно увидеть где есть перекос в превичном коде. (мне его не прогнать сейчас - всё время умирает расчёт..)<br>\n",
    "Идейно так: не всё сложные преобразования и модели могут помочь, лучше начинать с простого, смотреть что не работает, а потом наращивать слоность...<br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #cceeaa; padding: 5px; border: 1px solid green; border-radius: 5px;\">\n",
    "    <font color='blue'> <b><u>КОММЕНТАРИЙ РЕВЬЮЕРА</u></b>\n",
    "</font>\n",
    "<font color='green'><br>\n",
    "1) Загрузить данные - это ОК у тебя.<br>\n",
    "2) Провести чистку регулярными выражениями.<br>\n",
    "Например такими (тут всякое можно ещё посмотерть):<br>\n",
    "def clean_text(text):<br>\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)<br>\n",
    "    text = re.sub(r\"n't\", \" not \", text)<br>\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)<br>\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)<br>\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)<br>\n",
    "    text = text.strip(' ')<br>\n",
    "    return text<br><br>\n",
    "\n",
    "3) Провести лемматизацию (НО КСТАТИ - ЭТО МОЖНО И НЕ ДЕЛАТЬ - ИТОЖЕ ДОЛЖЕН БЫТЬ РЕЗУЛЬТАТ)<br>\n",
    "def w_lemmatize(text):<br>\n",
    "    lem_text = [lemmatizer.lemmatize(i) for i in w_tokenizer.tokenize(text)]<br>\n",
    "    lem_text = \" \".join(lem_text)<br>\n",
    "    return lem_text    <br><br>\n",
    "    \n",
    "4) провести векторизацию.<BR>\n",
    "nltk.download('stopwords')<BR>\n",
    "stopwords = set(nltk_stopwords.words('english'))<BR>\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)<BR>\n",
    "count_tf_idf.fit(corpus_train)<BR>\n",
    "f_train = count_tf_idf.transform(corpus_train)<BR>\n",
    "f_test = count_tf_idf.transform(corpus_test)<BR><BR>\n",
    "    \n",
    "5) А дальше логистическая регерессия, например<br>\n",
    "можно попробовать с праметрами \"из коробки\" - должно сработать даже так.<br>\n",
    "Если нет - попробовать гридсечем прогнать, например nfrbt gfhfvtnhs:<br>\n",
    "param_lr = {'random_state': [100500], 'solver': ['liblinear'], 'penalty': ['l1', 'l2'], \\<br>\n",
    "            'class_weight': ['balanced'], 'C': [5, 10]}<br><br>\n",
    "    \n",
    "В итоге метрика должна быть в районе 0,77.<br>\n",
    "\n",
    "БУДУ ЖДАТЬ ТВОИ КОММЕНТАРИЕВ!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Данные загружены и подготовлены\n",
    "- [ ]  Модели обучены\n",
    "- [ ]  Значение метрики *F1* не меньше 0.75\n",
    "- [ ]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
